{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1d91b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import transforms\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import cv2 as cv\n",
    "import shutil\n",
    "import random\n",
    "import torch\n",
    "import os\n",
    "\n",
    "#Para solucionar un posible problema con plt\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f94ce995",
   "metadata": {},
   "source": [
    "## Empezamos recortando las imagenes del dataset por el centroide de la figura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3970481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_image(image, debug = 0):\n",
    "    #Pasamos la imagen a una escala de grises\n",
    "    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    #Aplicamos un filtro gausiano para eliminar ruido\n",
    "    blur = cv.GaussianBlur(gray, (5, 5), 0)\n",
    "    #Convertimos la imagen a blanco y negro\n",
    "    ret, thresh = cv.threshold(blur, 75, 255, cv.THRESH_BINARY_INV)\n",
    "    #Mostramos la imagen si es necesario\n",
    "    if debug != 0:\n",
    "        cv.imwrite(\"filter.png\", thresh)\n",
    "    return ret, thresh\n",
    "\n",
    "def centroid(image, debug = 0):\n",
    "    #Encontramos todos los contornos\n",
    "    contours, hierarchies = cv.findContours(image, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if len(contours) != 0:  \n",
    "        #Escogemos el contorno con mayor area\n",
    "        c = max(contours, key = cv.contourArea)\n",
    "        #Realizamos el cálculo de los centroides\n",
    "        M = cv.moments(c)\n",
    "        if M['m00'] != 0:\n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])\n",
    "            if debug != 0:\n",
    "                print(f\"x: {cx} y: {cy}\")\n",
    "    return cx, cy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb35e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(path, new_path, type):\n",
    "    i = 0\n",
    "    for item in os.listdir(path):\n",
    "        if os.path.isfile(os.path.join(path, item)):\n",
    "            image = cv.imread(os.path.join(path, item))\n",
    "            if image is not None:\n",
    "                ret, thresh = filter_image(image)\n",
    "                cx, cy = centroid(thresh)\n",
    "                w = 215\n",
    "                imageOut = image[cy-w:cy+w+1, cx-w:cx+w+1]\n",
    "                #Renombramos los archivos\n",
    "                name = str(i) + \"_\" + type + \".png\"\n",
    "                i = i + 1\n",
    "                try:\n",
    "                    cv.imwrite(os.path.join(new_path, name), imageOut)\n",
    "                except:\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aa5681",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_fail_path = \"Dataset/Original/Sin Fallo\"\n",
    "fail_path = \"Dataset/Original/Con Fallo\"\n",
    "\n",
    "new_no_fail_path =  \"Dataset/Cortado/Sin Fallo\"\n",
    "new_fail_path =  \"Dataset/Cortado/Con Fallo\"\n",
    "\n",
    "if os.path.exists(new_no_fail_path): shutil.rmtree(new_no_fail_path)\n",
    "os.makedirs(new_no_fail_path)\n",
    "\n",
    "if os.path.exists(new_fail_path): shutil.rmtree(new_fail_path)\n",
    "os.makedirs(new_fail_path)\n",
    "\n",
    "crop(no_fail_path, new_no_fail_path, \"nofail\")\n",
    "crop(fail_path, new_fail_path, \"fail\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "317cc7ee",
   "metadata": {},
   "source": [
    "## Preparando el dataset para el entrenamiento de la red\n",
    "Comprobamos si disponemos de una GPU con cuda, en caso afirmativo la asignamos como dispositivo, de lo contrario el dispositivo predetermiando será la CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0194997",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print('Using PyTorch version:', torch.__version__, ' Device:', device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4af18a61",
   "metadata": {},
   "source": [
    "Definimos una función para dividir el dataset de forma aleatoria entre dos partes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51953c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(dataset, test_size):\n",
    "    L = len(dataset)\n",
    "    n_second = int(L*test_size)\n",
    "    n_first = L - n_second\n",
    "    first_split, second_split = random_split(dataset, lengths=[n_first, n_second])\n",
    "    return first_split, second_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "05586fbd",
   "metadata": {},
   "source": [
    "Establecemos la ruta en la que se encuentra el dataset y lo dividimos en entrenamiento (80%) y validación (20%), el dataset de pruebas será un 10% del dataset calculado para el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0418990",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"Dataset/Cortado\"\n",
    "dataset = torchvision.datasets.ImageFolder(DATASET_PATH)\n",
    "\n",
    "training_dataset, validation_dataset = split_data(dataset, test_size = 0.2)\n",
    "training_dataset, test_dataset = split_data(training_dataset, test_size = 0.1)\n",
    "\n",
    "print('Data for trainig: {}'.format(len(training_dataset)))\n",
    "print('Data for validation: {}'.format(len(validation_dataset)))\n",
    "print('Data for testing: {}'.format(len(test_dataset)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aef021dc",
   "metadata": {},
   "source": [
    "Definimos una clase que nos permite obtener elementos del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27f5d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubsetTransforms(Dataset):\n",
    "    def __init__(self, subset, transforms):\n",
    "        self.subset = subset\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.subset[idx]\n",
    "        return self.transforms(x), y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4af283e",
   "metadata": {},
   "source": [
    "Definimos el método show, para posteriormente poder mostrar un ejemplo visual del contenido del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9ea449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(dataset, N=5, labels=None, figsize=(20, 20)):\n",
    "    idxs = np.random.randint(0, len(dataset)-1, N)\n",
    "    fig, axs = plt.subplots(ncols=len(idxs), squeeze=False, figsize=figsize)\n",
    "\n",
    "    for i, idx in enumerate(idxs):\n",
    "        sample = dataset[idx]\n",
    "        if isinstance(sample, tuple): # Si el primer argumento forma parte del segundo\n",
    "            sample, label = sample\n",
    "            if isinstance(label, torch.TensorType):\n",
    "                label = int(label.item())\n",
    "            if labels:\n",
    "                label = labels[label]\n",
    "            axs[0, i].title.set_text(label)\n",
    "        axs[0, i].imshow(F.to_pil_image(sample))\n",
    "        axs[0, i].set(xticklabels = [], yticklabels = [], xticks = [], yticks = [])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3f0a2d8",
   "metadata": {},
   "source": [
    "Configurmos el tamaño del batch y realizamos técnicas de Data Augmentation mediante transformaciones (ajustes de tamaño, rotaciones, giros) para posteriormente convertir a tensor y normalizar, finalmente, se configuran los cargadores de datos de entrenamiento, validación y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae7ae90",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                                transforms.Resize((200,200)),\n",
    "                                transforms.RandomRotation(15),\n",
    "                                transforms.RandomHorizontalFlip(30),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])\n",
    "                               ])\n",
    "\n",
    "training_dataset = SubsetTransforms(training_dataset, transform)\n",
    "test_dataset = SubsetTransforms(test_dataset, transform)\n",
    "validation_dataset = SubsetTransforms(validation_dataset, transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=training_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb33ca2a",
   "metadata": {},
   "source": [
    "Mostramos un ejemplo de 5 imágenes aleatorias del dataset de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cc7a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_idx = {\"nofail\":1, \"fail\":0}\n",
    "idx_to_labels = {0: \"fail\", 1: \"nofail\"}\n",
    "\n",
    "show(training_dataset, labels=idx_to_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac4b9fc4",
   "metadata": {},
   "source": [
    "## Definimos las funciones para realizar el entrenamiento, validación y test de los diferentes modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef635fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, optimizer, criterion, log_interval=200):\n",
    "    #Ponemos el modelo en modo entrenamiento\n",
    "    model.train()\n",
    "    \n",
    "    #Para cada lote del dataset de entrenamiento\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        #Llevamos los datos al dispositivo disponible (GPU/CPU)\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        #Gradientes a cero (mejora de rendimiento)\n",
    "        optimizer.zero_grad() \n",
    "        #Pasamos los datos a traves de la red\n",
    "        output = model(data)\n",
    "        #Calculamos la perdida\n",
    "        loss = criterion(output, target)\n",
    "        #Realizamos el paso atrás\n",
    "        loss.backward()\n",
    "        #Actualizamos los pesos\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5d6c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(loss_vector, accuracy_vector, model, criterion):\n",
    "    #Ponemos el modelo en modo evaluación\n",
    "    model.eval()\n",
    "    val_loss, correct = 0, 0\n",
    "    \n",
    "    #Para todo el dataset de validacción\n",
    "    for data, target in validation_loader:\n",
    "        #Llevamos los datos al dispositivo disponible (GPU/CPU)\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        #Pasamos los datos a traves de la red\n",
    "        output = model(data)\n",
    "        #Calculamos e incrementamos la peridida de validación\n",
    "        val_loss += criterion(output, target).data.item()\n",
    "        #Obtenemos la prediccción del dato (la mayor clase)\n",
    "        pred = output.data.max(1)[1]\n",
    "        #Si la predicccioón es correcta, aumentamos el acierto\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "    #Añadimos los resultados al vector de perdidas\n",
    "    val_loss /= len(validation_loader)\n",
    "    loss_vector.append(val_loss)\n",
    "    #Añadimos los resultados al vector de aciertos\n",
    "    accuracy = 100. * correct.to(torch.float32) / len(validation_loader.dataset)\n",
    "    accuracy_vector.append(accuracy)\n",
    "\n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        val_loss, correct, len(validation_loader.dataset), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac66d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    #Ponemos el modelo en modo evaluación\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    #Como no estamos entrenando, desactivamos los gradientes para mejorar el rendimiento\n",
    "    with torch.no_grad():\n",
    "        #Para todo el dataset de prueba\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            #Pasamos los datos a traves de la red\n",
    "            outputs = model.cpu()\n",
    "            outputs = model(images)\n",
    "            #Escogemos la predicción (la mayor clase)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            #Calculamos los resultados de las predicciones\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    print(f'Accuracy of the network on the test images: {100 * correct // total}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b34b155",
   "metadata": {},
   "source": [
    "## Creamos dos modelos de red diferentes: \n",
    "### ResNet18\n",
    "Aprovechando el transfer learrning tomamos un modelo de ResNet18 ya pre-entrenado, a este modelo se le añade una última capa lineal para que se ajuste a nuestro situación (solamente tenemos dos clases de salida), además re-entrenamos la capa 4 que hará que nuestra red se ajuste mejor a nuestro problema y entrenamos la última capa que acabamos de añadir, esto se consigue facilmente desactivando los gradientes del resto de capa que no necesitan entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a6e072",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.model = torchvision.models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "        self.model.fc = nn.Linear(512, 2)\n",
    "        #Solo entrenamos las capas definidas en unfreeze\n",
    "        unfreeze = ['layer4', 'fc']\n",
    "        for layer_name, layer in self.model.named_parameters():\n",
    "            for name in unfreeze:\n",
    "                if name in layer_name:\n",
    "                    layer.requires_grad = True\n",
    "                    break\n",
    "                else:\n",
    "                    layer.requires_grad = False\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0d8d16f",
   "metadata": {},
   "source": [
    "### MyNet\n",
    "A continuación definimos otro modelo de red. Va a contar con 3 capas de convolucionales con función de activación RELU y Batch Normalization, posteriormente 3 capas ocultas full connected, todas ellas cuentan con una función de activación RELU, ademas ceunta con una función de dropout con una probabilidad del 35%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be2c4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3,16,kernel_size=3, padding=0,stride=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16,32, kernel_size=3, padding=0, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "            )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32,64, kernel_size=3, padding=0, stride=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(256,512)\n",
    "        self.dropout = nn.Dropout(0.35)\n",
    "        self.fc2 = nn.Linear(512,128)\n",
    "        self.fc3 = nn.Linear(128,2)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        \n",
    "    def forward(self,x): \n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0),-1) #Recolocamos el tensor en una sola dimensión\n",
    "        out = self.relu(self.fc1(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(self.fc2(out)) #Última capa con 2 salidas correspondientes a las dos clases posibles\n",
    "        out = self.fc3(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83d00747",
   "metadata": {},
   "source": [
    "Cargamos el modelo y optimizador para los dos modelos definidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af12538a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = MyNet().to(device)\n",
    "my_model_optimizer = torch.optim.Adam(my_model.parameters(), lr=2e-4, betas=(0.9, 0.999), eps=1e-8)\n",
    "\n",
    "resnet_model = ResNet().to(device)\n",
    "resnet_optimizer = torch.optim.Adam(resnet_model.parameters(), lr=2e-4, betas=(0.9, 0.999), eps=1e-8)\n",
    "\n",
    "#Será la misma para los dos modelos\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#print(my_model)\n",
    "#print(resnet_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a28e0988",
   "metadata": {},
   "source": [
    "## Entrenamiento de los modelos\n",
    "Realizamos el entrenamiento de la red \"MyNet\" durante 10 épocas mediante las funciones anteriormente definidas \"train\" y \"validate\", posteriormente realizamos un test del modelo con datos que la red nunca antes ha visto, guardamos el modelo y graficamos los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde0fec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "epochs = 10\n",
    "\n",
    "lossv, accv = [], []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch, my_model, my_model_optimizer, criterion)\n",
    "    validate(lossv, accv, my_model, criterion)\n",
    "test(my_model)\n",
    "torch.save(my_model, 'my_model.pt')\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(np.arange(1,epochs+1), lossv, label='loss')\n",
    "plt.title('validation loss')\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(np.arange(1,epochs+1), accv)\n",
    "plt.title('validation accuracy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9cfa1213",
   "metadata": {},
   "source": [
    "Realizamos el entrenamiento de la red \"ResNet18\" durante 10 épocas mediante las funciones anteriormente definidas \"train\" y \"validate\", posteriormente realizamos un test del modelo con datos que la red nunca antes ha visto, guardamos el modelo y graficamos los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c101ddbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "epochs = 10\n",
    "\n",
    "lossv, accv = [], []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch, resnet_model, resnet_optimizer, criterion)\n",
    "    validate(lossv, accv, resnet_model, criterion)\n",
    "test(resnet_model)\n",
    "torch.save(resnet_model, 'resnet_model.pt')\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(np.arange(1,epochs+1), lossv, label='loss')\n",
    "plt.title('validation loss')\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(np.arange(1,epochs+1), accv)\n",
    "plt.title('validation accuracy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7f0ac28",
   "metadata": {},
   "source": [
    "## Producto final\n",
    "Esta función será la que reciba el cliente (comentando una linea, pero que por ahora nos sirve para hacer mas pruebas), como no tenemos imágenes adicionales hacemos la prueba con 5 imagenes aleatorias sacadas del dataset de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4811ca2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isFail(samples):\n",
    "    labels_to_idx = {\"nofail\":1, \"fail\":0}\n",
    "    idx_to_labels = {0: \"fail\", 1: \"nofail\"}\n",
    "\n",
    "    model = torch.load('my_model.pt')\n",
    "\n",
    "    for i in range(len(samples)):\n",
    "        sample = samples[i]\n",
    "        image, label = sample\n",
    "        category = idx_to_labels[label] #Comentando esta linea sería lo que recibe el cliente\n",
    "    \n",
    "        input_image = image.unsqueeze(0)\n",
    "        model=my_model.cpu()\n",
    "        model_output = model(input_image)\n",
    "        prediction = torch.argmax(torch.softmax(model_output, -1)).item()\n",
    "        predicted_category = idx_to_labels[prediction]\n",
    "    \n",
    "        print(f'Predicción:{predicted_category} | Actual:{category}')\n",
    "\n",
    "N=5\n",
    "random_indices = np.random.randint(0, len(test_dataset)-1, N)\n",
    "random_samples = [test_dataset[i] for i in random_indices]\n",
    "\n",
    "isFail(random_samples)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "d9637665aa80e77104db02ec0629c5c9ee9f67c95c85b703d7a1361244bba5f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
